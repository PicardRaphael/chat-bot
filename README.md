# ğŸ¤– RaphaÃ«l PICARD - AI Assistant

Un assistant IA personnel basÃ© sur OpenAI GPT-4 et Gemini, avec une architecture modulaire et des fonctionnalitÃ©s avancÃ©es d'Ã©valuation et de retry.

## ğŸš€ FonctionnalitÃ©s

- ğŸ’¬ **Chat interactif** avec interface Gradio Ã©lÃ©gante
- ğŸ”„ **SystÃ¨me de retry intelligent** avec stratÃ©gies multiples
- ğŸ“Š **Ã‰valuation automatique** des rÃ©ponses avec Gemini
- ğŸ¯ **Profil personnalisÃ©** basÃ© sur CV et informations LinkedIn
- âš™ï¸ **Configuration flexible** via variables d'environnement
- ğŸ“ˆ **Logging et mÃ©triques** pour monitoring
- ğŸ—ï¸ **Architecture modulaire** pour faciliter la maintenance

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- ClÃ©s API OpenAI et Google (Gemini)
- Fichiers de profil (PDF LinkedIn, rÃ©sumÃ© texte)

## ğŸ› ï¸ Installation

### 1. Cloner et naviguer

```bash
git clone git@github.com:PicardRaphael/chat-bot.git
cd chat-bot/
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. Configuration des variables d'environnement

CrÃ©er un fichier `.env` :

```bash
# API Keys (obligatoires)
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...

# Configuration optionnelle
CHAT_MODEL=gpt-4o-mini
EVALUATION_MODEL=gemini-2.0-flash
PROFILE_DIR=raph/files
LOG_LEVEL=INFO
```

### 4. PrÃ©parer les fichiers de profil

Placer dans le dossier `raph/files/` :

- `linkedin.pdf` : Export du profil LinkedIn en PDF
- `summary.txt` : RÃ©sumÃ© personnel en texte

## ğŸš€ Utilisation

### Interface simple

```bash
python main.py
```

### Interface avancÃ©e avec onglets

```bash
python main.py --advanced
```

### Options de ligne de commande

```bash
python main.py --help

Options:
  --advanced    Interface avancÃ©e avec configuration et mÃ©triques
  --share       CrÃ©er un lien public Gradio
  --port 8080   Port personnalisÃ© (dÃ©faut: 7860)
  --host 0.0.0.0  Host personnalisÃ© (dÃ©faut: 127.0.0.1)
```

### Exemples d'utilisation

```bash
# Interface simple sur localhost
python main.py

# Interface avancÃ©e avec partage public
python main.py --advanced --share

# Interface sur le rÃ©seau local, port 8080
python main.py --host 0.0.0.0 --port 8080
```

## ğŸ—ï¸ Architecture

### Structure du projet

```
raph/
â”œâ”€â”€ ğŸ“ config/                 # Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py            # Variables d'environnement centralisÃ©es
â”‚   â””â”€â”€ prompts.py             # Templates de prompts
â”œâ”€â”€ ğŸ“ core/                   # Logique mÃ©tier centrale
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py              # Classes Pydantic (donnÃ©es structurÃ©es)
â”‚   â”œâ”€â”€ profile_loader.py      # Chargement des donnÃ©es de profil
â”‚   â””â”€â”€ message_formatter.py   # Formatage des messages OpenAI
â”œâ”€â”€ ğŸ“ services/               # Services mÃ©tier
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ services/chat_service.py        # Service principal de chat
â”‚   â”œâ”€â”€ evaluation_service.py  # Ã‰valuation des rÃ©ponses
â”‚   â””â”€â”€ retry_service.py       # StratÃ©gies de retry intelligentes
â”œâ”€â”€ ğŸ“ api/                    # Clients API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ openai_client.py       # Client OpenAI configurÃ©
â”‚   â””â”€â”€ gemini_client.py       # Client Gemini pour Ã©valuation
â”œâ”€â”€ ğŸ“ ui/                     # Interface utilisateur
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ gradio_interface.py    # Interface Gradio complÃ¨te
â”œâ”€â”€ ğŸ“ utils/                  # Utilitaires
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_utils.py          # Lecture de fichiers (PDF, texte)
â”‚   â””â”€â”€ logger.py              # Configuration des logs
â”œâ”€â”€ ğŸ“„ main.py                 # Point d'entrÃ©e principal
â”œâ”€â”€ ğŸ“„ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ test_tasks.py          # Tests de validation
â””â”€â”€ ğŸ“„ README.md              # Cette documentation
```

### Flux de donnÃ©es

```mermaid
graph TB
    A["ğŸ‘¤ Utilisateur"] --> B["ğŸ¨ Gradio Interface"]
    B --> C["ğŸ’¬ Chat Service"]
    C --> D["ğŸ“ Message Formatter"]
    D --> E["ğŸ¤– OpenAI Client"]
    E --> F["ğŸ“Š Evaluation Service"]
    F --> G["ğŸ”„ Retry Service"]
    G --> H["âœ¨ RÃ©ponse finale"]
    H --> B

    I["ğŸ“ Profile Loader"] --> C
    J["âš™ï¸ Settings"] --> C
    K["ğŸ“‹ Prompts"] --> C
    L["ğŸ—ƒï¸ File Utils"] --> I
    M["ğŸ“Š Logger"] --> C
```

## ğŸ§© Composants principaux

### ğŸ’¬ Chat Service

Service principal qui orchestre la gÃ©nÃ©ration de rÃ©ponses :

- IntÃ©gration avec le profil utilisateur
- Gestion des prompts systÃ¨me
- Pipeline complet : gÃ©nÃ©ration â†’ Ã©valuation â†’ retry si nÃ©cessaire

### ğŸ”„ Retry Service

SystÃ¨me intelligent de retry avec plusieurs stratÃ©gies :

- **SINGLE** : Une seule tentative de retry
- **MULTIPLE** : Plusieurs tentatives avec Ã©valuation
- **PROGRESSIVE** : DÃ©lais progressifs entre tentatives
- **BEST_OF_N** : GÃ©nÃ¨re N rÃ©ponses et sÃ©lectionne la meilleure

### ğŸ“Š Evaluation Service

Ã‰valuation automatique des rÃ©ponses via Gemini :

- CritÃ¨res de qualitÃ© personnalisables
- Feedback dÃ©taillÃ© pour amÃ©lioration
- SÃ©lection automatique des meilleures rÃ©ponses

### ğŸ¨ Gradio Interface

Interface utilisateur avec deux modes :

- **Simple** : Chat basique et Ã©purÃ©
- **AvancÃ©** : Onglets avec configuration et mÃ©triques

## âš™ï¸ Configuration

### Variables d'environnement

| Variable            | Description                      | DÃ©faut             |
| ------------------- | -------------------------------- | ------------------ |
| `OPENAI_API_KEY`    | ClÃ© API OpenAI                   | _(obligatoire)_    |
| `GOOGLE_API_KEY`    | ClÃ© API Google                   | _(obligatoire)_    |
| `CHAT_MODEL`        | ModÃ¨le OpenAI pour le chat       | `gpt-4o-mini`      |
| `EVALUATION_MODEL`  | ModÃ¨le Gemini pour l'Ã©valuation  | `gemini-2.0-flash` |
| `PROFILE_DIR`       | Dossier des fichiers de profil   | `raph/files`       |
| `MAX_RETRIES`       | Nombre maximum de retry          | `3`                |
| `ENABLE_EVALUATION` | Activer l'Ã©valuation automatique | `True`             |
| `LOG_LEVEL`         | Niveau de logging                | `INFO`             |

### Fichiers de configuration

- `.env` : Variables d'environnement
- `config/settings.py` : Configuration centralisÃ©e
- `config/prompts.py` : Templates de prompts personnalisables

## ğŸ§ª Tests et validation

### Lancer les tests

```bash
python test_tasks.py
```

Les tests valident :

- âœ… Configuration et chargement des settings
- âœ… Fonctionnement des services (chat, Ã©valuation, retry)
- âœ… IntÃ©gration des clients API
- âœ… Interface Gradio
- âœ… Formatage des messages
- âœ… Chargement du profil

### Tests de performance

Les tests incluent la validation des mÃ©triques :

- Temps de rÃ©ponse
- Taux de succÃ¨s des retry
- QualitÃ© des Ã©valuations

## ğŸ“Š Monitoring et logs

### Structure des logs

```
2025-06-26 10:57:16 [INFO] raph_chatbot: ğŸš€ Starting: chat operation
2025-06-26 10:57:16 [INFO] raph_chatbot: âœ… Completed: chat operation
```

### MÃ©triques disponibles

- **Temps de rÃ©ponse** moyen par requÃªte
- **Taux de succÃ¨s** des Ã©valuations
- **Nombre de retry** par conversation
- **Performance** des diffÃ©rents modÃ¨les

### Context managers pour le logging

```python
from utils.logger import LogContext, EvaluationLogContext

# Logging d'opÃ©ration
with LogContext("chat_generation"):
    response = generate_response(message)

# Logging d'Ã©valuation
with EvaluationLogContext("user_message", response, True):
    # Ã‰valuation automatiquement loggÃ©e
    pass
```

## ğŸ”§ Personnalisation

### Ajouter un nouveau modÃ¨le

1. Modifier `config/settings.py` :

```python
CHAT_MODEL: str = "gpt-4o"  # Nouveau modÃ¨le
```

2. RedÃ©marrer l'application

### Personnaliser les prompts

Modifier `config/prompts.py` :

```python
SYSTEM_PROMPT = """
Vous Ãªtes un assistant personnalisÃ© pour {name}.
[Votre prompt personnalisÃ© ici]
"""
```

### Ajouter une nouvelle stratÃ©gie de retry

1. Modifier `services/retry_service.py`
2. Ajouter la stratÃ©gie dans `RetryStrategy` enum
3. ImplÃ©menter la logique dans `retry_with_strategy()`

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

**Erreur "API key not found"**

- VÃ©rifier le fichier `.env`
- S'assurer que les clÃ©s API sont valides

**Erreur "Profile files not found"**

- VÃ©rifier la prÃ©sence de `linkedin.pdf` et `summary.txt` dans `raph/files/`
- ContrÃ´ler le chemin dans `PROFILE_DIR`

**Interface Gradio ne dÃ©marre pas**

- VÃ©rifier que le port n'est pas dÃ©jÃ  utilisÃ©
- Essayer avec `--port 8080`

### Logs de dÃ©bogage

Activer le mode debug :

```bash
export LOG_LEVEL=DEBUG
python main.py
```

### Tests de connectivitÃ©

```python
from api.openai_client import get_openai_client
from api.gemini_client import get_gemini_client

# Test OpenAI
openai_client = get_openai_client()
print(openai_client.test_connection())

# Test Gemini
gemini_client = get_gemini_client()
print(gemini_client.test_connection())
```

## ğŸš€ DÃ©veloppement

### Ajouter une nouvelle fonctionnalitÃ©

1. **Service** : CrÃ©er dans `services/`
2. **ModÃ¨les** : Ajouter dans `core/models.py`
3. **Tests** : Ajouter dans `test_tasks.py`
4. **Interface** : Modifier `ui/gradio_interface.py`

### Structure recommandÃ©e pour un nouveau service

```python
"""Module de description du service."""

from typing import Optional
from utils.logger import logger
from config.settings import settings

class MonService:
    """Description du service."""

    def __init__(self):
        """Initialisation."""
        self.setting = settings.MON_SETTING
        logger.debug("MonService initialized")

    def ma_methode(self) -> str:
        """Description de la mÃ©thode."""
        try:
            # Logique ici
            return "rÃ©sultat"
        except Exception as e:
            logger.error(f"Erreur dans ma_methode: {e}")
            raise

# Singleton pattern
_mon_service: Optional[MonService] = None

def get_mon_service() -> MonService:
    """Obtenir l'instance singleton."""
    global _mon_service
    if _mon_service is None:
        _mon_service = MonService()
    return _mon_service
```

## ğŸ“„ Licence

Ce projet est un assistant personnel et n'est pas destinÃ© Ã  un usage commercial.

## ğŸ‘¤ Auteur

**RaphaÃ«l PICARD**

- Assistant IA personnel dÃ©veloppÃ© pour optimiser les interactions et fournir des rÃ©ponses contextuelles basÃ©es sur le profil professionnel.

---

_Documentation gÃ©nÃ©rÃ©e automatiquement lors du refactoring - Phase 5 complÃ¨te_ âœ¨
