# ğŸ¤– RaphaÃ«l PICARD - AI Assistant

Un assistant IA personnel basÃ© sur OpenAI GPT-4 et Gemini, avec une architecture modulaire et des fonctionnalitÃ©s avancÃ©es d'Ã©valuation et de retry.

## ğŸš€ FonctionnalitÃ©s

- ğŸ’¬ **Chat interactif** avec interface Gradio Ã©lÃ©gante
- ğŸ”„ **SystÃ¨me de retry intelligent** avec stratÃ©gies multiples
- ğŸ“Š **Ã‰valuation automatique** des rÃ©ponses avec Gemini
- ğŸ¯ **Profil personnalisÃ©** basÃ© sur CV et informations LinkedIn
- ğŸ› ï¸ **Function Calling & Tools** - SystÃ¨me de tools automatiques
- ğŸ“¬ **Notifications Pushover** pour enregistrer les questions inconnues
- âš™ï¸ **Configuration flexible** via variables d'environnement
- ğŸ“ˆ **Logging et mÃ©triques** pour monitoring
- ğŸ—ï¸ **Architecture modulaire** pour faciliter la maintenance

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- ClÃ©s API OpenAI et Google (Gemini)
- Fichiers de profil (PDF LinkedIn, rÃ©sumÃ© texte)

## ğŸ› ï¸ Installation

### 1. Cloner et naviguer

```bash
git clone git@github.com:PicardRaphael/chat-bot.git
cd chat-bot/
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. Configuration des variables d'environnement

CrÃ©er un fichier `.env` :

```bash
# API Keys (obligatoires)
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...

# Pushover (pour tools/notifications)
PUSHOVER_USER=your_pushover_user_key
PUSHOVER_TOKEN=your_pushover_app_token

# Configuration optionnelle
CHAT_MODEL=gpt-4o-mini
EVALUATION_MODEL=gemini-2.0-flash
PROFILE_DIR=raph/files
LOG_LEVEL=INFO
```

### 4. PrÃ©parer les fichiers de profil

Placer dans le dossier `raph/files/` :

- `linkedin.pdf` : Export du profil LinkedIn en PDF
- `summary.txt` : RÃ©sumÃ© personnel en texte

## ğŸš€ Utilisation

### Interface simple

```bash
python main.py
```

### Interface avancÃ©e avec onglets

```bash
python main.py --advanced
```

### Options de ligne de commande

```bash
python main.py --help

Options:
  --advanced    Interface avancÃ©e avec configuration et mÃ©triques
  --share       CrÃ©er un lien public Gradio
  --port 8080   Port personnalisÃ© (dÃ©faut: 7860)
  --host 0.0.0.0  Host personnalisÃ© (dÃ©faut: 127.0.0.1)
```

### Exemples d'utilisation

```bash
# Interface simple sur localhost
python main.py

# Interface avancÃ©e avec partage public
python main.py --advanced --share

# Interface sur le rÃ©seau local, port 8080
python main.py --host 0.0.0.0 --port 8080
```

## ğŸ—ï¸ Architecture

### Structure du projet

```
raph/
â”œâ”€â”€ ğŸ“ config/                 # Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py            # Variables d'environnement centralisÃ©es
â”‚   â”œâ”€â”€ prompts.py             # Templates de prompts
â”‚   â””â”€â”€ pushover.py            # Templates des tools Pushover
â”œâ”€â”€ ğŸ“ core/                   # Logique mÃ©tier centrale
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py              # Classes Pydantic (donnÃ©es structurÃ©es)
â”‚   â”œâ”€â”€ profile_loader.py      # Chargement des donnÃ©es de profil
â”‚   â””â”€â”€ message_formatter.py   # Formatage des messages OpenAI
â”œâ”€â”€ ğŸ“ services/               # Services mÃ©tier
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chat_service.py        # Service principal de chat
â”‚   â”œâ”€â”€ evaluation_service.py  # Ã‰valuation des rÃ©ponses
â”‚   â”œâ”€â”€ retry_service.py       # StratÃ©gies de retry intelligentes
â”‚   â””â”€â”€ tools_service.py       # Orchestrateur des tools/function calling
â”œâ”€â”€ ğŸ“ api/                    # Clients API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ openai_client.py       # Client OpenAI configurÃ©
â”‚   â”œâ”€â”€ gemini_client.py       # Client Gemini pour Ã©valuation
â”‚   â””â”€â”€ pushover_client.py     # Client Pushover pour notifications
â”œâ”€â”€ ğŸ“ ui/                     # Interface utilisateur
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ gradio_interface.py    # Interface Gradio complÃ¨te
â”œâ”€â”€ ğŸ“ utils/                  # Utilitaires
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_utils.py          # Lecture de fichiers (PDF, texte)
â”‚   â””â”€â”€ logger.py              # Configuration des logs
â”œâ”€â”€ ğŸ“„ main.py                 # Point d'entrÃ©e principal
â”œâ”€â”€ ğŸ“„ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ test_tasks.py          # Tests de validation
â””â”€â”€ ğŸ“„ README.md              # Cette documentation
```

### Flux de donnÃ©es

```mermaid
graph TB
    A["ğŸ‘¤ Utilisateur"] --> B["ğŸ¨ Gradio Interface"]
    B --> C["ğŸ’¬ Chat Service"]
    C --> D["ğŸ“ Message Formatter"]
    D --> E["ğŸ¤– OpenAI Client"]
    E --> F["ğŸ› ï¸ Tools Service"]
    F --> G["ğŸ“¬ Pushover Client"]
    E --> H["ğŸ“Š Evaluation Service"]
    H --> I["ğŸ”„ Retry Service"]
    I --> J["âœ¨ RÃ©ponse finale"]
    J --> B

    K["ğŸ“ Profile Loader"] --> C
    L["âš™ï¸ Settings"] --> C
    M["ğŸ“‹ Prompts"] --> C
    N["ğŸ—ƒï¸ File Utils"] --> K
    O["ğŸ“Š Logger"] --> C
    P["ğŸ”§ Tool Templates"] --> F
```

## ğŸ§© Composants principaux

### ğŸ’¬ Chat Service

Service principal qui orchestre la gÃ©nÃ©ration de rÃ©ponses :

- IntÃ©gration avec le profil utilisateur
- Gestion des prompts systÃ¨me
- Pipeline complet : gÃ©nÃ©ration â†’ Ã©valuation â†’ retry si nÃ©cessaire

### ğŸ”„ Retry Service

SystÃ¨me intelligent de retry avec plusieurs stratÃ©gies :

- **SINGLE** : Une seule tentative de retry
- **MULTIPLE** : Plusieurs tentatives avec Ã©valuation
- **PROGRESSIVE** : DÃ©lais progressifs entre tentatives
- **BEST_OF_N** : GÃ©nÃ¨re N rÃ©ponses et sÃ©lectionne la meilleure

### ğŸ“Š Evaluation Service

Ã‰valuation automatique des rÃ©ponses via Gemini :

- CritÃ¨res de qualitÃ© personnalisables
- Feedback dÃ©taillÃ© pour amÃ©lioration
- SÃ©lection automatique des meilleures rÃ©ponses

### ğŸ¨ Gradio Interface

Interface utilisateur avec deux modes :

- **Simple** : Chat basique et Ã©purÃ©
- **AvancÃ©** : Onglets avec configuration et mÃ©triques

## ğŸ› ï¸ SystÃ¨me de Tools (Function Calling)

L'assistant intÃ¨gre un systÃ¨me de **function calling** permettant Ã  l'IA d'exÃ©cuter automatiquement des actions externes en fonction du contexte de la conversation.

### ğŸ¯ Fonctionnement

```mermaid
graph TB
    A["ğŸ‘¤ User Query"] --> B["ğŸ¤– OpenAI GPT-4o-mini"]
    B --> C{"ğŸ” Tool Call Required?"}
    C -->|"Yes"| D["ğŸ› ï¸ Tool Execution"]
    C -->|"No"| E["ğŸ’¬ Direct Response"]
    D --> F["ğŸ“¬ External Action<br/>(Pushover, etc.)"]
    F --> G["ğŸ”„ Continue Conversation"]
    G --> E
    E --> H["ğŸ“¤ Final Response"]
```

### ğŸ“‹ Tools disponibles

| Tool                      | DÃ©clencheur                                | Action                                    |
| ------------------------- | ------------------------------------------ | ----------------------------------------- |
| `record_unknown_question` | Question sans rÃ©ponse connue               | ğŸ“¬ Notification Pushover de la question   |
| `record_user_details`     | Utilisateur fournit email/infos de contact | ğŸ“¬ Notification Pushover avec les dÃ©tails |

### âš™ï¸ Configuration des Tools

#### Variables d'environnement requises

Ajouter dans votre fichier `.env` :

```bash
# Pushover (pour notifications)
PUSHOVER_USER=your_pushover_user_key
PUSHOVER_TOKEN=your_pushover_app_token
```

#### Obtenir les clÃ©s Pushover

1. **CrÃ©er un compte** sur [pushover.net](https://pushover.net)
2. **User Key** : Disponible sur le dashboard principal
3. **App Token** : CrÃ©er une nouvelle application dans "Your Applications"

### ğŸ“¬ Tools Pushover

#### `record_unknown_question`

**DÃ©clenchement automatique** :

- L'IA ne connaÃ®t pas la rÃ©ponse Ã  une question
- Information non prÃ©sente dans le profil/CV
- Question sortant du domaine de compÃ©tence

**Exemple** :

```
User: "Quel est ton film prÃ©fÃ©rÃ© ?"
IA: "Je ne trouve pas cette information dans mon profil. Laisse-moi enregistrer cette question..."
ğŸ”§ Tool Call â†’ record_unknown_question("Quel est ton film prÃ©fÃ©rÃ© ?")
ğŸ“¬ Pushover â†’ "Recording question asked that I couldn't answer: Quel est ton film prÃ©fÃ©rÃ© ?"
```

#### `record_user_details`

**DÃ©clenchement automatique** :

- Utilisateur partage son email
- Demande de contact ou collaboration
- IntÃ©rÃªt exprimÃ© pour un projet

**Exemple** :

```
User: "Je suis intÃ©ressÃ© par ton profil, mon email est john@example.com"
ğŸ”§ Tool Call â†’ record_user_details(email="john@example.com", name="John", notes="IntÃ©rÃªt pour le profil")
ğŸ“¬ Pushover â†’ "Recording interest from John with email john@example.com and notes IntÃ©rÃªt pour le profil"
```

### ğŸ—ï¸ Architecture des Tools

```
services/
â”œâ”€â”€ tools_service.py         # Orchestrateur principal des tools
api/
â”œâ”€â”€ pushover_client.py       # Client Pushover
config/
â”œâ”€â”€ pushover.py             # Templates des tools Pushover
```

#### Structure d'un Tool

Format OpenAI Function Calling :

```json
{
  "type": "function",
  "function": {
    "name": "record_unknown_question",
    "description": "Always use this tool to record any question that couldn't be answered",
    "parameters": {
      "type": "object",
      "properties": {
        "question": {
          "type": "string",
          "description": "The question that couldn't be answered"
        }
      },
      "required": ["question"]
    }
  }
}
```

### ğŸ”§ Ajouter de nouveaux Tools

#### 1. CrÃ©er le client API

```python
# api/mon_service_client.py
class MonServiceClient:
    def execute_tool(self, tool_name: str, **kwargs) -> dict:
        if tool_name == "mon_action":
            return self.mon_action(**kwargs)

    def mon_action(self, param1: str) -> dict:
        # Logique d'exÃ©cution
        return {"success": True}

    def mon_service_tools(self) -> List[Dict[str, Any]]:
        return [
            {
                "type": "function",
                "function": {
                    "name": "mon_action",
                    "description": "Description de l'action",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "param1": {
                                "type": "string",
                                "description": "Description du paramÃ¨tre"
                            }
                        },
                        "required": ["param1"]
                    }
                }
            }
        ]
```

#### 2. IntÃ©grer dans ToolsService

```python
# services/tools_service.py
def __init__(self):
    self.pushover_client = get_pushover_client()
    self.mon_service_client = get_mon_service_client()  # Nouveau

def get_all_tools(self):
    tools = []
    # Pushover tools
    tools.extend(self.pushover_client.pushover_tools())
    # Nouveaux tools
    tools.extend(self.mon_service_client.mon_service_tools())
    return tools
```

### ğŸ› DÃ©pannage des Tools

#### Erreurs courantes

**"Missing required parameter: 'tools[0].type'"**

- VÃ©rifier le format JSON des tools
- S'assurer que `"type": "function"` est prÃ©sent

**"Tool execution failed"**

- VÃ©rifier les variables d'environnement (PUSHOVER_USER, PUSHOVER_TOKEN)
- ContrÃ´ler les logs pour identifier l'erreur spÃ©cifique

**Tools non appelÃ©s**

- VÃ©rifier que les tools sont bien chargÃ©s avec `get_all_tools()`
- S'assurer que le prompt systÃ¨me encourage l'utilisation des tools

#### Tests de validation

```python
# Test des tools
from services.tools_service import get_all_tools, execute_tool

# VÃ©rifier le chargement
tools = get_all_tools()
print(f"Tools disponibles: {len(tools)}")

# Test d'exÃ©cution
result = execute_tool("record_unknown_question", question="Test question")
print(f"RÃ©sultat: {result}")
```

## ğŸ›ï¸ Architecture : LLM-as-a-Judge

Ce systÃ¨me implÃ©mente le pattern **"LLM-as-a-Judge with Retry Logic"**, une architecture robuste utilisÃ©e dans les systÃ¨mes de production pour garantir la qualitÃ© des rÃ©ponses.

### Principe de fonctionnement

```mermaid
graph LR
    A["ğŸ‘¤ User Query"] --> B["ğŸ¤– Generator LLM<br/>(OpenAI GPT-4o-mini)"]
    B --> C["ğŸ’­ Response"]
    C --> D["âš–ï¸ Judge LLM<br/>(Gemini 2.0-flash)"]
    D --> E{"âœ… Acceptable?"}
    E -->|"Yes"| F["ğŸ“¤ Final Response"]
    E -->|"No"| G["ğŸ”„ Retry with Feedback"]
    G --> B
```

### Avantages de cette approche

- **ğŸ¯ QualitÃ© garantie** : Double validation par des modÃ¨les diffÃ©rents
- **ğŸ”„ Auto-correction** : AmÃ©lioration itÃ©rative avec feedback
- **âš–ï¸ RÃ©duction des biais** : Validation croisÃ©e entre modÃ¨les
- **ğŸ“Š MÃ©triques** : TraÃ§abilitÃ© complÃ¨te du processus

### Composants clÃ©s

| RÃ´le            | ModÃ¨le             | ResponsabilitÃ©                         |
| --------------- | ------------------ | -------------------------------------- |
| **Generator**   | OpenAI GPT-4o-mini | GÃ©nÃ¨re les rÃ©ponses conversationnelles |
| **Judge**       | Gemini 2.0-flash   | Ã‰value la qualitÃ© et pertinence        |
| **Retry Logic** | Custom Service     | Orchestre les tentatives avec feedback |

### Pattern reconnu dans l'industrie

Cette architecture est Ã©galement connue sous les noms :

- **LLM-as-a-Judge** (terme le plus courant)
- **Critic-Generator Architecture**
- **Multi-Model Validation**
- **Self-Correcting AI with External Judge**

## âš™ï¸ Configuration

### Variables d'environnement

| Variable            | Description                      | DÃ©faut             |
| ------------------- | -------------------------------- | ------------------ |
| `OPENAI_API_KEY`    | ClÃ© API OpenAI                   | _(obligatoire)_    |
| `GOOGLE_API_KEY`    | ClÃ© API Google                   | _(obligatoire)_    |
| `PUSHOVER_USER`     | User Key Pushover pour tools     | _(optionnel)_      |
| `PUSHOVER_TOKEN`    | App Token Pushover pour tools    | _(optionnel)_      |
| `CHAT_MODEL`        | ModÃ¨le OpenAI pour le chat       | `gpt-4o-mini`      |
| `EVALUATION_MODEL`  | ModÃ¨le Gemini pour l'Ã©valuation  | `gemini-2.0-flash` |
| `PROFILE_DIR`       | Dossier des fichiers de profil   | `raph/files`       |
| `MAX_RETRIES`       | Nombre maximum de retry          | `3`                |
| `ENABLE_EVALUATION` | Activer l'Ã©valuation automatique | `True`             |
| `LOG_LEVEL`         | Niveau de logging                | `INFO`             |

### Fichiers de configuration

- `.env` : Variables d'environnement
- `config/settings.py` : Configuration centralisÃ©e
- `config/prompts.py` : Templates de prompts personnalisables

## ğŸ§ª Tests et validation

### Lancer les tests

```bash
python test_tasks.py
```

Les tests valident :

- âœ… Configuration et chargement des settings
- âœ… Fonctionnement des services (chat, Ã©valuation, retry)
- âœ… IntÃ©gration des clients API
- âœ… Interface Gradio
- âœ… Formatage des messages
- âœ… Chargement du profil

### Tests de performance

Les tests incluent la validation des mÃ©triques :

- Temps de rÃ©ponse
- Taux de succÃ¨s des retry
- QualitÃ© des Ã©valuations

## ğŸ“Š Monitoring et logs

### Structure des logs

```
2025-06-26 10:57:16 [INFO] raph_chatbot: ğŸš€ Starting: chat operation
2025-06-26 10:57:16 [INFO] raph_chatbot: âœ… Completed: chat operation
```

### MÃ©triques disponibles

- **Temps de rÃ©ponse** moyen par requÃªte
- **Taux de succÃ¨s** des Ã©valuations
- **Nombre de retry** par conversation
- **Performance** des diffÃ©rents modÃ¨les

### Context managers pour le logging

```python
from utils.logger import LogContext, EvaluationLogContext

# Logging d'opÃ©ration
with LogContext("chat_generation"):
    response = generate_response(message)

# Logging d'Ã©valuation
with EvaluationLogContext("user_message", response, True):
    # Ã‰valuation automatiquement loggÃ©e
    pass
```

## ğŸ”§ Personnalisation

### Ajouter un nouveau modÃ¨le

1. Modifier `config/settings.py` :

```python
CHAT_MODEL: str = "gpt-4o"  # Nouveau modÃ¨le
```

2. RedÃ©marrer l'application

### Personnaliser les prompts

Modifier `config/prompts.py` :

```python
SYSTEM_PROMPT = """
Vous Ãªtes un assistant personnalisÃ© pour {name}.
[Votre prompt personnalisÃ© ici]
"""
```

### Ajouter une nouvelle stratÃ©gie de retry

1. Modifier `services/retry_service.py`
2. Ajouter la stratÃ©gie dans `RetryStrategy` enum
3. ImplÃ©menter la logique dans `retry_with_strategy()`

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

**Erreur "API key not found"**

- VÃ©rifier le fichier `.env`
- S'assurer que les clÃ©s API sont valides

**Erreur "Profile files not found"**

- VÃ©rifier la prÃ©sence de `linkedin.pdf` et `summary.txt` dans `raph/files/`
- ContrÃ´ler le chemin dans `PROFILE_DIR`

**Interface Gradio ne dÃ©marre pas**

- VÃ©rifier que le port n'est pas dÃ©jÃ  utilisÃ©
- Essayer avec `--port 8080`

**Erreurs liÃ©es aux Tools**

- **"PUSHOVER_USER environment variable is required"** : Ajouter les variables Pushover dans `.env`
- **"Missing required parameter: 'tools[0].type'"** : ProblÃ¨me de format des tools, vÃ©rifier `config/pushover.py`
- **Tools non appelÃ©s** : VÃ©rifier que le prompt systÃ¨me encourage l'utilisation des tools

### Logs de dÃ©bogage

Activer le mode debug :

```bash
export LOG_LEVEL=DEBUG
python main.py
```

### Tests de connectivitÃ©

```python
from api.openai_client import get_openai_client
from api.gemini_client import get_gemini_client
from services.tools_service import get_all_tools, execute_tool

# Test OpenAI
openai_client = get_openai_client()
print(openai_client.test_connection())

# Test Gemini
gemini_client = get_gemini_client()
print(gemini_client.test_connection())

# Test Tools
tools = get_all_tools()
print(f"Tools disponibles: {len(tools)}")

# Test Pushover (si configurÃ©)
try:
    result = execute_tool("record_unknown_question", question="Test de connectivitÃ©")
    print(f"Test Pushover: {result}")
except Exception as e:
    print(f"Pushover non configurÃ©: {e}")
```

## ğŸš€ DÃ©veloppement

### Ajouter une nouvelle fonctionnalitÃ©

1. **Service** : CrÃ©er dans `services/`
2. **ModÃ¨les** : Ajouter dans `core/models.py`
3. **Tests** : Ajouter dans `test_tasks.py`
4. **Interface** : Modifier `ui/gradio_interface.py`

### Structure recommandÃ©e pour un nouveau service

```python
"""Module de description du service."""

from typing import Optional
from utils.logger import logger
from config.settings import settings

class MonService:
    """Description du service."""

    def __init__(self):
        """Initialisation."""
        self.setting = settings.MON_SETTING
        logger.debug("MonService initialized")

    def ma_methode(self) -> str:
        """Description de la mÃ©thode."""
        try:
            # Logique ici
            return "rÃ©sultat"
        except Exception as e:
            logger.error(f"Erreur dans ma_methode: {e}")
            raise

# Singleton pattern
_mon_service: Optional[MonService] = None

def get_mon_service() -> MonService:
    """Obtenir l'instance singleton."""
    global _mon_service
    if _mon_service is None:
        _mon_service = MonService()
    return _mon_service
```

## ğŸ“„ Licence

Ce projet est un assistant personnel et n'est pas destinÃ© Ã  un usage commercial.

## ğŸ‘¤ Auteur

**RaphaÃ«l PICARD**

- Assistant IA personnel dÃ©veloppÃ© pour optimiser les interactions et fournir des rÃ©ponses contextuelles basÃ©es sur le profil professionnel.

---

_Documentation gÃ©nÃ©rÃ©e automatiquement lors du refactoring - Phase 5 complÃ¨te_ âœ¨
